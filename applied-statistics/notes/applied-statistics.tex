\documentclass[a4paper]{article}
\usepackage[T1]{fontenc}			% \chapter package
\usepackage[english]{babel}
\usepackage[english]{isodate}  		% date format
\usepackage{graphicx}				% manage images
\usepackage{amsfonts}
\usepackage{booktabs}				% high quality tables
\usepackage{amsmath}				% math package
\usepackage{amssymb}				% another math package (e.g. \nexists)
\usepackage{bm}                     % bold math symbols
\usepackage{mathtools}				% emphasize equations
\usepackage{stmaryrd} 				% '\llbracket' and '\rrbracket'
\usepackage{amsthm}					% better theorems
\usepackage{enumitem}				% manage list
\usepackage{pifont}					% nice itemize
\usepackage{cancel}					% cancel math equations
\usepackage{caption}				% custom caption
\usepackage[]{mdframed}				% box text
\usepackage{multirow}				% more lines in a table
\usepackage{textcomp, gensymb}		% degree symbol
\usepackage[x11names]{xcolor}		% RGB color
\usepackage{tcolorbox}				% colorful box
\usepackage{multicol}				% more rows in a table (used for the lists)
\usepackage{listings}
\usepackage{url}
\usepackage{qrcode}
\usepackage{fontawesome5}
\usepackage{ragged2e}
\usepackage{cite}                   % references
\usepackage{imakeidx}               % index
\makeindex[program=makeindex, columns=2,
           title=Index, 
           intoc,
           options={-s index-style.ist}]


\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}


% draw a frame around given text
\newcommand{\framedtext}[1]{%
	\par%
	\noindent\fbox{%
		\parbox{\dimexpr\linewidth-2\fboxsep-2\fboxrule}{#1}%
	}%
}


% table of content links
\usepackage{xcolor}
\usepackage[linkcolor=black, citecolor=blue, urlcolor=cyan]{hyperref} % hypertexnames=false
\hypersetup{
	colorlinks=true
}


\newtheorem{theorem}{\textcolor{Red3}{\underline{Theorem}}}
\renewcommand{\qedsymbol}{QED}
\newcommand{\dquotes}[1]{``#1''}
\newcommand{\longline}{\noindent\rule{\textwidth}{0.4pt}}
\newcommand{\circledtext}[1]{\raisebox{.5pt}{\textcircled{\raisebox{-.9pt}{#1}}}}
\newcommand{\definition}[1]{\textcolor{Red3}{\textbf{#1}}\index{#1}}
\newcommand{\example}[1]{\textcolor{Green4}{\textbf{#1}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Bias}{\mathrm{Bias}}
\newcommand{\highspace}{\vspace{1.2em}\noindent}


\begin{document}
    \newcounter{definition}[section]
    \newcounter{example}[section]
    
    \newtcolorbox[use counter = definition]{definitionbox}{%
        colback=red!5!white,
        colframe=red!75!black,
        fonttitle=\bfseries,
        title=Definition \thetcbcounter %
    }
    
    \newtcolorbox[use counter = example]{examplebox}{%
        colback=Green4!5!white,
        colframe=Green4!75!black,
        fonttitle=\bfseries,
        title=Example \thetcbcounter %
    }

    \author{260236}
	\title{Applied Statistics - Notes}
	\date{\printdayoff\today}
	\maketitle

	\newpage

    \section*{Preface}

    Every theory section in these notes has been taken from two sources:
    \begin{itemize}
        \item \href{https://www.statlearning.com/}{An Introduction to Statistical Learning}\cite{james2013introduction}
        \item Applied Multivariate Statistical Analysis (sixth edition).\cite{johnson2007applied}
    \end{itemize}
    About:
    \begin{itemize}
        \item[\faIcon{github}] \href{https://github.com/AndreVale69/HPC-E-PoliMI-university-notes}{GitHub repository}
    \end{itemize}
    
    \newpage
	
	\tableofcontents
	
	\newpage

    \section{Sample Geometry}

    \subsection{The Geometry of the Sample}

    \underline{A single} \definition{multivariate observation} is the \textbf{collection of measurements on $p$ different variables taken on the same item or trial}. If \textbf{$n$ observations} have been obtained, the entire data set can be placed in an $n \times p$ array (or matrix), also called \definition{data frame}:
    \begin{equation}\label{eq: data frame matrix}
        \underset{\left(n \times p\right)}{\mathbf{X}} = \begin{bmatrix}
            x_{11} & x_{12} & \cdots & x_{1p} \\
            x_{21} & x_{22} & \cdots & x_{2p} \\
            \vdots & \vdots & \ddots & \vdots \\
            x_{n1} & x_{n2} & \cdots & x_{np}
        \end{bmatrix}
    \end{equation}
    Each \textbf{row} of $\mathbf{X}$ represents a \textbf{multivariate observation}. Since the entire data frame is often one particular realization of what might have been observed, we say that the data frame are a \textbf{sample of size $n$ from a $p$-variate \dquotes{population}}. The sample then consists of $n$ measurements, each of which has $p$ components.

    Look at the matrix, $n$ measurements (rows), each of which has $p$ components (columns). In mathematics, each $n$ row contains $p$ columns and vice versa.
    
    \highspace
    The data frame can be plotted in two different ways:
    \begin{enumerate}
        \item $p$-dimensional scatter plot, where the rows represent $n$ points in \emph{p}-dimensional space;
        \item Geometrical representation, $p$ vectors in $n$-dimensional space.
    \end{enumerate}
    
    \longline

    \subsubsection{Scatter plot}

    For the \definition{$p$-dimensional scatter plot}, the rows of $\mathbf{X}$ represent $n$ points in $p$-dimensional space:
    \begin{equation}\label{eq: p-dimensional scatter plot}
        \underset{\left(n \times p\right)}{\mathbf{X}} = \begin{bmatrix}
            x_{11} & x_{12} & \cdots & x_{1p} \\
            x_{21} & x_{22} & \cdots & x_{2p} \\
            \vdots & \vdots & \ddots & \vdots \\
            x_{n1} & x_{n2} & \cdots & x_{np}
        \end{bmatrix} = \left[\begin{array}{@{} c @{}}
            \mathbf{x}_{1}' \\
            \mathbf{x}_{2}' \\
            \vdots \\
            \mathbf{x}_{n}'
        \end{array}\right]
        \begin{array}{l}
            \leftarrow \text{1st (multivariate) observation} \\
            \phantom{\mathbf{x}_{2}'} \\
            \phantom{\vdots} \\
            \leftarrow n\text{th (multivariate) observation}
        \end{array}
    \end{equation}
    The row vector $\mathbf{x}_{j}'$, representing the $j$th observation, contains the coordinates of a point. The \textbf{scatter plot} of $n$ points in $p$-dimensional space \textbf{provides information} on the \textbf{locations and variability of the points}.
    
    \highspace
    \underline{\textbf{Note}}: when $p$ (dimensional space) is greater than $3$, the \textbf{scatter plot} representation cannot actually be graphed. Yet the consideration of the data as $n$ points in $p$ dimensions provides \textbf{insights that are not readily available from algebraic expressions}.

    \newpage

    \subsubsection{Geometrical representation}

    The alternative \definition{geometrical representation} is constructed by considering the data as \textbf{$p$ vectors in $n$-dimensional space}. Here we take the elements of the columns of the data frame to be the coordinates of the vectors:
    \begin{equation}\label{eq: geometrical representation}
        \underset{\left(n \times p\right)}{\mathbf{X}} = \begin{bmatrix}
            x_{11} & x_{12} & \cdots & x_{1p} \\
            x_{21} & x_{22} & \cdots & x_{2p} \\
            \vdots & \vdots & \ddots & \vdots \\
            x_{n1} & x_{n2} & \cdots & x_{np}
        \end{bmatrix} = \left[\mathbf{y}_{1} \: | \: \mathbf{y}_{2} \: | \: \cdots \: | \: \mathbf{y}_{p}\right]
    \end{equation}
    Then the \textbf{coordinates} of the first point $\mathbf{y}_{1} = \left[x_{11}, x_{21}, \dots, x_{n1}\right]$ \textbf{are the $n$ measurements} on the first variable. 
    
    In general, the $i$th point $\mathbf{y}_{i} = \left[x_{11}, x_{21}, \dots, x_{n1}\right]$ is determined by the $n$-tuple of all measurements on the $i$th variable.
    
    \highspace
    \textbf{Geometrical representations} usually \textbf{facilitate understanding} and lead to further insights. The ability to \textbf{relate algebraic expressions to the geometric concepts} of length, angle and volume is therefore \textbf{very important}.
    
    \highspace
    \longline

    \subsubsection{Geometrical interpretation of the process of finding a sample mean}

    Before starting the explanation, you need to understand a few things.
    \begin{itemize}
        \item The \definition{length} of a vector $\mathbf{x}'=\left[x_{1}, x_{2}, \dots, x_{n}\right]$ with $n$ components is defined by:
        \begin{equation}\label{eq: length of a vector}
            L_{x} = \sqrt{x_{1}^{2} + x_{2}^{2} + \cdots + x_{n}^{2}}
        \end{equation}
        Multiplication of a vector $\mathbf{x}$ by a scalar $c$ changes the length:
        \begin{equation*}
            \begin{array}{rcl}
                L_{cx} &=& \sqrt{c^{2} \cdot x_{1}^{2} + c^{2} \cdot x_{2}^{2} + \cdots + c^{2} \cdot x_{n}^{2}} \\ [.3em]
                %
                &=& \left| c \right| \sqrt{x_{1}^{2} + x_{2}^{2} + \cdots + x_{n}^{2}} \\ [.3em] 
                %
                &=& \left| c \right| L_{x}
            \end{array}
        \end{equation*}
        So, for example, in $n = 2$ dimensions, the vector:
        \begin{equation*}
            \mathbf{x} = \begin{bmatrix}
                x_{1} \\ x_{2}
            \end{bmatrix}
        \end{equation*}
        The length of $\mathbf{x}$, written $L_{x}$, is defined to be:
        \begin{equation*}
            L_{x} = \sqrt{x_{1}^{2} + x_{2}^{2}}
        \end{equation*}

        \newpage

        \item Another important concept is \definition{angle}. Consider two vectors in a plane and the angle $\theta$ between them:
        \begin{figure}[!htp]
            \centering
            \includegraphics[width=.7\textwidth]{img/basics-vector-algebra-1.pdf}
            \caption{The angle $\theta$ between $\mathbf{x}' = \left[x_{1}, x_{2}\right]$ and $\mathbf{y}' = \left[y_{1}, y_{2}\right]$.}
        \end{figure}
        The value $\theta$ can be represented as the difference between the angles $\theta_{1}$ and $\theta_{2}$ formed by the two vectors and the first coordinate axis. Since, by definition:
        \begin{gather*}
            \begin{array}{rcl}
                \cos\left(\theta_{1}\right) = \dfrac{x_{1}}{L_{x}} & \cos\left(\theta_{2}\right) = \dfrac{y_{1}}{L_{y}} \\ [1em]
                %
                \sin\left(\theta_{1}\right) = \dfrac{x_{2}}{L_{x}} & \sin\left(\theta_{2}\right) = \dfrac{y_{2}}{L_{y}}
            \end{array} \\
            \cos\left(\theta\right) = \cos\left(\theta_{2} - \theta_{1}\right) = \cos\left(\theta_{2}\right) \cos\left(\theta_{1}\right) + \sin\left(\theta_{2}\right) \sin\left(\theta_{1}\right)
        \end{gather*}
        The angle $\theta$ between the two vectors $\mathbf{x}' = \left[x_{1}, x_{2}\right]$ and $\mathbf{y}' = \left[y_{1}, y_{2}\right]$ is specified by:
        \begin{equation}\label{eq: angle}
            \cos\left(\theta\right) = \cos\left(\theta_{2} - \theta_{1}\right) = 
            \left(\dfrac{y_{1}}{L_{y}}\right)\left(\dfrac{x_{1}}{L_{x}}\right) + \left(\dfrac{y_{2}}{L_{y}}\right)\left(\dfrac{x^{2}}{L_{x}}\right) =
            \dfrac{x_{1}y_{1} + x_{2}y_{2}}{L_{x}L_{y}}
        \end{equation}

        \item With the angle equation~\ref{eq: angle}, it's convenient to introduce the \definition{inner product} of two vectors:
        \begin{equation*}
            \mathbf{x}\mathbf{y}' = x_{1}y_{1} + x_{2}y_{2}
        \end{equation*}
        So let us rewrite:
        \begin{itemize}
            \item The \textbf{length} equation~\ref{eq: length of a vector}:
            \begin{equation}\label{eq: length rewritten with inner product}
                \mathbf{x}'\mathbf{x} = x_{1} x_{1} + x_{1} x_{1} = x_{1}^{2} + x_{2}^{2} 
                \longrightarrow
                L_{x} = \sqrt{x_{1}^{2} + x_{2}^{2}}
                \Longrightarrow
                L_{x} = \sqrt{\mathbf{x}' \mathbf{x}}
            \end{equation}

            \item The \textbf{angle} equation~\ref{eq: angle}:
            \begin{equation*}
                \cos\left(\theta\right) = \dfrac{x_{1}y_{1} + x_{2}y_{2}}{L_{x}L_{y}} 
                \Longrightarrow
                \cos\left(\theta\right) = \dfrac{\mathbf{x}'\mathbf{y}}{L_{x}L_{y}}
            \end{equation*}
            And using the rewritten length equation:
            \begin{equation*}
                \cos\left(\theta\right) = \dfrac{\mathbf{x}'\mathbf{y}}{L_{x}L_{y}} \Longrightarrow
                \cos\left(\theta\right) = \dfrac{\mathbf{x}'\mathbf{y}}{\sqrt{\mathbf{x}' \mathbf{x}} \cdot \sqrt{\mathbf{y}' \mathbf{y}}}
            \end{equation*}
        \end{itemize}
        
        \item The \definition{projection} (or shadow) of a vector $\mathbf{x}$ on a vector $\mathbf{y}$ is:
        \begin{equation}\label{eq: projection}
            \dfrac{\left(\mathbf{x}'\mathbf{y}\right)}{\mathbf{y}'\mathbf{y}}\mathbf{y} = \dfrac{\left(\mathbf{x}'\mathbf{y}\right)}{L_{y}}\dfrac{1}{L_{y}}\mathbf{y}
        \end{equation}
        Where the vector $\dfrac{1}{L_{y}}\mathbf{y}$ has unit length. The \textbf{length of the projection} is:
        \begin{equation}\label{eq: length of the projection}
            \dfrac{\left| \mathbf{x}'\mathbf{y} \right|}{L_{y}} = L_{x} \left| \dfrac{\mathbf{x}'\mathbf{y}}{L_{x}L_{y}} \right| = L_{x} \left| \cos\left(\theta\right) \right|
        \end{equation}
        Where $\theta$ is the angle between $\mathbf{x}$ and $\mathbf{y}$:
        \begin{figure}[!htp]
            \centering
            \includegraphics[width=.7\textwidth]{img/basics-vector-algebra-2.pdf}
            \caption{The projection of $\mathbf{x}$ on $\mathbf{y}$.}
        \end{figure}
    \end{itemize}
    Start by defining the $n \times 1$ vector $\mathbf{1}_{n}' = \left[1, 1, \dots, 1\right]$. The vector $\mathbf{1}$ forms equal angles with each of the $n$ coordinates axes, so the vector $\left(\dfrac{1}{\sqrt{n}}\right)\mathbf{1}$ has unit length in the equal-angle direction. Consider the vector $\mathbf{y}_{i}' = \left[x_{1i}, x_{2i}, \dots, x_{ni}\right]$. The projection of $\mathbf{y}_{i}$ on the unit vector $\left(\dfrac{1}{\sqrt{n}}\right)\mathbf{1}$ is:
    \begin{equation}\label{eq: sample mean - geometrical representation}
        \mathbf{y}_{i}'\left(\dfrac{1}{\sqrt{n}}\mathbf{1}\right)\dfrac{1}{\sqrt{n}}\mathbf{1} = 
        \dfrac{x_{1i} + x_{2i} + \cdots + x_{ni}}{n}\mathbf{1} = \overline{x}_{i}\mathbf{1}
    \end{equation}
    Although it may seem like a complex equation at first glance, it is nothing more than the mean! In fact, the \textbf{sample mean} $\overline{\mathbf{x}}_{i} = \dfrac{\left(x_{1i} + x_{2i} + \cdots + x_{ni}\right)}{n} = \dfrac{\mathbf{y}_{i}' \mathbf{1}}{n}$ corresponds to the multiple of $\mathbf{1}$ required to give the projection of $\mathbf{y}_{i}$ onto the line determined by $\mathbf{1}$.\newpage

    \noindent
    Furthermore, using the projection, you can obtain the \textbf{deviation} (\textbf{mean corrected}). For each $\mathbf{y}_{i}$ we have the decomposition:
    \begin{figure}[!htp]
        \centering
        \includegraphics[width=.6\textwidth]{img/basics-vector-algebra-3.pdf}
    \end{figure}

    \noindent
    Where $\overline{x}_{i} \mathbf{1}$ is perpendicular to $y_{i}-\overline{x}_{i}\mathbf{1}$. The \definition{deviation}, or \definition{mean corrected}, vector is:
    \begin{equation}\label{eq: deviation - mean corrected}
        \mathbf{d}_{i} = \mathbf{y}_{i} - \overline{x}_{i}\mathbf{1} = \begin{bmatrix}
            x_{1i} - \overline{x}_{i} \\
            x_{2i} - \overline{x}_{i} \\
            \vdots \\
            x_{ni} - \overline{x}_{i}
        \end{bmatrix}
    \end{equation}
    The \textbf{elements} of $\mathbf{d}_{i}$ are the \textbf{deviations of the measurements on the} $\bm{i}$\textbf{th variable from their sample mean}.\newline

    \noindent
    Using the length rewritten with inner product (equation~\ref{eq: length rewritten with inner product}) and the deviation (equation~\ref{eq: deviation - mean corrected}), we obtain:
    \begin{equation}
        L_{\mathbf{d}_{i}}^{2} = \mathbf{d}_{i}'\mathbf{d}_{i} = \displaystyle\sum_{j=1}^{n}\left(x_{ji}-\overline{x}_{i}\right)^{2}
    \end{equation}
    \begin{equation*}
        \left(\text{Length of deviation vector}\right)^{2} = \text{sum of squared deviations}
    \end{equation*}
    From the sample standard deviation, we see that the \textbf{squared length is proportional to the variance} of the measurements on the $i$th variable. Equivalently, the \textbf{length is proportional to the standard deviation}. So longer vectors represent more variability than shorter vectors.

    Furthermore, for any two deviation vectors $\mathbf{d}_{i}$ and $\mathbf{d}_{k}$:
    \begin{equation}
        \mathbf{d}_{i}'\mathbf{d}_{k} = \displaystyle\sum_{j=1}^{n}\left(x_{ji} - \overline{x}_{i}\right)\left(x_{jk} - \overline{x}_{k}\right)
    \end{equation}
    And with a few mathematical operations, we can get it:
    \begin{equation}
        r_{ik} = \dfrac{s_{ik}}{\sqrt{s_{ii}}\sqrt{s_{kk}}} = \cos\left(\theta_{ik}\right)
    \end{equation}
    Where the \textbf{cosine} of the angle is the \definition{sample correlation coefficient}. Note: $s_{ik}$ is the \definition{sample covariance}:
    \begin{equation}\label{eq: sample covariance}
        s_{ik} = \dfrac{1}{n} \displaystyle\sum_{j=1}^{n} \left(x_{ji} - \overline{x}_{i}\right)\left(x_{jk} - \overline{x}_{k}\right) \hspace{2em} i = 1,2,\dots,p, \hspace{1em} k = 1,2,\dots,p
    \end{equation}
    Thus:
    \begin{itemize}
        \item If the two deviation vectors have \textbf{nearly the same orientation}, the sample correlation will be close to $1$;
        \item If the two vectors are \textbf{nearly perpendicular}, the sample correlation will be approximately zero;
        \item If the two vectors are oriented in \textbf{nearly opposite directions}, the sample correlation will be close to $-1$.
    \end{itemize}

    \longline

    \subsection{Generalized Variance}

    Before starting the explanation, you need to understand what is a sample variance.

    A \definition{sample variance} is defined as:
    \begin{equation}\label{eq: sample variance}
        s_{k}^{2} = s_{kk} = \dfrac{1}{n-1} \displaystyle\sum_{j=1}^{n} \left(x_{jk} - \overline{x}_{k}\right)^{2} \hspace{2em} k = 1, 2, \dots, p
    \end{equation}

    With a single variable, the \textbf{sample variance is often used to describe the amount of variation in the measurements on that variable}. When $p$ variables are observed on each unit, the variation is described by the \definition{sample variance-covariance matrix}:
    \begin{equation}
        \mathbf{S} = \begin{bmatrix}
            s_{11} & s_{12} & \cdots & s_{1p} \\
            s_{21} & s_{22} & \cdots & s_{2p} \\
            \vdots & \vdots & \ddots & \vdots \\
            s_{p1} & s_{p2} & \cdots & s_{pp}
        \end{bmatrix} =
        \left\{s_{ik} = \dfrac{1}{n-1}\displaystyle\sum_{j=1}^{n}\left(x_{ji}-\overline{x}_{i}\right)\left(x_{jk}-\overline{x}_{k}\right)\right\}
    \end{equation}
    The sample covariance matrix contains $p$ variances and $\dfrac{1}{2}p\left(p-1\right)$ potentially different covariances. Sometimes it's desirable to \textbf{assign a single numerical value for the variation expressed by $\mathbf{S}$}. One choice for a value is the \href{https://en.wikipedia.org/wiki/Determinant}{determinant} of $\mathbf{S}$, which reduces to the usual sample variance of a single characteristic when $p=1$. This determinant is called the \definition{generalized sample variance}:
    \begin{equation}
        \text{Generalized sample variance} = \det\left(\mathbf{S}\right) = \left| \mathbf{S} \right|
    \end{equation}
    
    \newpage

    \section{Statistical Learning}

    \subsection{Introduction}

    Suppose that we observe a quantitative response $Y$ and $p$ different predictors, $X_{1}, X_{2}, \dots, X_{p}$. We assume that there is some relationship between $Y$ and $X = \left(X_{1}, X_{2}, \dots, X_{p}\right)$, which can be written in the general form:
    \begin{equation}\label{eq: error term systematic}
        Y = f\left(X\right) + \varepsilon
    \end{equation}
    Where $\varepsilon$ is an \definition{error term}, which is \textbf{independent} of $X$ and has \textbf{mean zero}. The function $f$ represents the \definition{systematic information} that $X$ provides about $Y$. The \textbf{function} $f$ that connects the input variables to the output variable \textbf{is in general unknown}.
    
    \begin{figure}[!htp]
        \begin{examplebox}
            For \example{example}, on the left-hand panel of figure~\ref{fig: error term systematic}, a plot \texttt{income} versus \texttt{years of education} for 30 individuals in the Income data set.
            
            \begin{center}
                \includegraphics[width=\textwidth]{img/error-term-systematic-1.pdf}
                \captionof{figure}{The \texttt{Income} data set.\cite{james2013introduction}}
                \label{fig: error term systematic}
            \end{center}


            \noindent
            As you can see, the plot suggests that one might be able to predict \texttt{income} using \texttt{years of education}. Since \texttt{Income} is a simulated data set, the function $f$ is known and is shown by the blue curve in the right-hand panel. The \textbf{vertical lines} represent the \textbf{error terms} $\varepsilon$. We note that some of the 30 observations lie above the blue curve and some lie below it; overall, the \textbf{errors have approximately mean zero}.
        \end{examplebox}
    \end{figure}

    \noindent
    In essence, \textbf{statistical learning refers to a set of approaches for estimating $f$}. In this chapter we outline some of the key theoretical concepts that arise in estimating $f$.

    \newpage

    \subsection{Why Estimate \emph{f} (systematic information provided by a predictor about a quantitative response)?}

    There are two main reasons that we may wish to estimate $f$\index{systematic information}: \definition{prediction} and \definition{inference}.

    \longline

    \subsubsection{Prediction}\label{subsubsection: prediction}

    In many situations, a set of inputs $X$ are readily available, but the output $Y$ cannot be easily obtained. In this setting, since the error term $\varepsilon$ averages to zero, we can predict $Y$ using:
    \begin{equation}
        \hat{Y} = \hat{f}\left(X\right)
    \end{equation}
    \begin{itemize}
        \item $\hat{f}$ represents our \textbf{estimate for} $\bm{f}$
        \item $\hat{Y}$ represents \definition{prediction} for $Y$
    \end{itemize}
    The function $\hat{f}$ is often treated as a \textbf{black box}, in the sense that one is not typically concerned with the exact form of $\hat{f}$, provided that \textbf{it yields accurate predictions for} $Y$.

    \begin{examplebox}
        As an \example{example}, suppose that:
        \begin{itemize}
            \item $X_{1}, \dots, X_{p}$ are \textbf{characteristics of a patient's blood sample} that can be easily measured in a lab.
            \item $Y$ is a variable encoding the \textbf{patient's risk for a severe adverse reaction to a particular drug}.
        \end{itemize}
        It is natural to seek to predict $Y$ using $X$, since we can then avoid giving the drug in question to patients who are at high risk of an adverse reaction. That is, patients for whom the estimate of $Y$ is high.
    \end{examplebox}

    \noindent
    The accuracy of $\hat{Y}$ as a prediction for $Y$ depends on two quantities: \definition{reducible error} and \definition{irreducible error}.
    \begin{itemize}
        \item In general, $\hat{f}$ will not be a perfect estimate for $f$, and this \textbf{inaccuracy} will introduce some error. This is a \definition{reducible error} because we can potentially \textbf{improve the accuracy of $\bm{\hat{f}}$ by using the most appropriate statistical learning technique to estimate $\bm{f}$}.
        
        \item Even if it were possible to form a perfect estimate for $f$, so that our estimated response took the form $\hat{Y} = f\left(X\right)$, our prediction would still have some error in it! This is because $Y$ is also a function of $\varepsilon$ (error term), which, by definition, cannot be predicted using $X$. Therefore, variability associated with $\varepsilon$ also affects the accuracy of our predictions. This is the \definition{irreducible error}, because \textbf{no matter how well we estimate $\bm{f}$, we cannot reduce the error introduced by $\bm{\varepsilon}$}.
    \end{itemize}
    The real question is: \emph{why is the irreducible error larger than zero?} Well, the quantity $\varepsilon$ may contain unmeasured variables that are useful in predicting $Y$: since we don't measure them, $f$ cannot use them for its prediction. The quantity $\varepsilon$ may also contain unmeasurable variation.

    \begin{examplebox}
        For \example{example}, the risk of an adverse reaction might vary for a given patient on a given day, depending on manufacturing variation in the drug itself or the patient's general feeling of well-being on that day.
    \end{examplebox}

    \noindent
    Consider a given estimate $\hat{f}$ and a set of predictors $X$, which yields the prediction $\hat{Y} = \hat{f}\left(X\right)$. Assume for a moment that both $\hat{f}$ and $X$ are fixed, so that the only variability comes from $\varepsilon$ (error term). Then, it's easy to show that:
    \begin{equation}\label{eq: reducible and irreducible error}
        \begin{array}{rcl}
            E\left(Y - \hat{Y}\right)^{2} &=& E\left[f\left(X\right) + \varepsilon - \hat{f}\left(X\right)\right]^{2} \\ [1em]
                                          &=& \underbrace{\left[f\left(X\right) - \hat{f}\left(X\right)\right]^{2}}_{\text{Reducible}} + \underbrace{\Var\left(\varepsilon\right)}_{\text{Irreducible}}
        \end{array}
    \end{equation}
    \begin{itemize}
        \item $\left[f\left(X\right) - \hat{f}\left(X\right)\right]^{2}$ represents the \textbf{squared difference between the predicted and actual value of} $\bm{Y}$
        
        \item $E\left(Y-\hat{Y}\right)^{2}$ represents the \textbf{average}, or \definition{exprected value}
        
        \item $\Var\left(\varepsilon\right)$ represents the \definition{variance} \textbf{associated with the error term} $\bm{\varepsilon}$
    \end{itemize}
    The focus of this course is on \emph{techniques} for estimating $f$ with the aim of \textbf{minimizing the reducible error}. It is important to keep in mind that the irreducible error will always provide an upper bound on the accuracy of our prediction for $Y$. Unfortunately, this bound is almost always unknown in practice.

    \begin{examplebox}
        Consider a company that is interested in conducting a direct-marketing campaign.

        The \emph{goal} is to identify individuals who are likely to respond positively to a mailing, based on observations of demographic variables measured on each individual.

        In this case:
        \begin{itemize}
            \item The demographic variables serve as \emph{predictors};
            \item Response to the marketing campaign (either positive or negative) serves as the \emph{outcome}.
        \end{itemize}
        The company is \underline{not} interested in obtaining a deep understanding of the relationships between each individual predictor and the response; instead, the company simply \textbf{wants to accurately predict the response using the predictors}.

        This is an example of \textbf{modeling for prediction}.
    \end{examplebox}

    \subsubsection{Inference}\index{inference}\label{subsubsection: inference}

    We are often interested in understanding the association between $Y$ (quantitative response) and $X_{1}, \dots, X_{p}$ ($p$-predictors). In this situation we wish to estimate $f$ (systematic information), but our goal is not necessarily to make predictions for $Y$. Now it's obviously that $\hat{f}$ cannot be treated as a black box, because we need to know its exact form. In this setting, one may be interested in \textbf{answering the following questions}:
    \begin{itemize}
        \item \example{\emph{Which predictors are associated with the response?}} It is often the case that only a small fraction of the available predictors are substantially associated with $Y$. So, \textbf{identifying} the few \textbf{important predictors among a large set of possible variables can be extremely useful}.

        \item \example{\emph{What is the relationship between the response and each predictor?}} Larger values of the predictor are associated with larger values of $Y$. Other predictors may have the opposite relationship. The relationship between the response and the given predictor may \textbf{depend} on:
        \begin{itemize}
            \item The \textbf{complexity} of $f$;
            \item The \textbf{values of the other predictors}.
        \end{itemize}

        \item \example{\emph{Can the relationship between $Y$ and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?}} Historically, \textbf{most methods} for estimating $f$ \textbf{have} taken \textbf{linear form}. But often the true relationship is more complicated, in which case a \textbf{linear model may not provide an accurate representation} of the relationship between the input and the output variables.
    \end{itemize}

    \begin{examplebox}
        Modeling the brand of a product that a customer might purchased based on variables such as:
            \begin{itemize}
                \item Price
                \item Store
                \item Location
                \item Discount levels
                \item Competition price
            \end{itemize}
        And so forth. In this situation one might really be most interested in the \textbf{association between each variable and the probability of purchase}. For instance, \emph{to what extent is the product's price associated with sales?}

        This is an example of \textbf{modeling for inference}.
    \end{examplebox}

    \begin{figure}[!htp]
        \begin{examplebox}
            Consider the following figure:
            \begin{center}
                \includegraphics[width=\textwidth]{img/statistical-learning-1.pdf}
                \captionof{figure}{The \texttt{Advertising} data set. The plot displays \texttt{sales}, in thousands of units, as a function of \texttt{TV}, \texttt{radio}, and \texttt{newspaper} budgets, in thousands of dollars, for 200 different markets. In each plot we show the simple least squares fit of \texttt{sales} to that variable. In other words, each blue line represents a simple model that can be used to predict \texttt{sales} using \texttt{TV}, \texttt{radio}, and \texttt{newspaper}, respectively.}
            \end{center}
            One may be interested in answering questions such as:
            \begin{itemize}
                \item \emph{Which media are associated with sales?}
                \item \emph{Which media generate the biggest boost in sales?}
                \item \emph{How large of an increase in sales is associated with a given increase in TV advertising?}
            \end{itemize}
            This situation falls into the \textbf{inference model}.
        \end{examplebox}
    \end{figure}

    \subsubsection{Difference between prediction and inference}

    \begin{examplebox}
        In a real estate setting, one may seek to relate values of homes to inputs such as:
        \begin{itemize}
            \item Crime rate
            \item Zoning
            \item Distance from a river
            \item Air quality
            \item Schools
            \item Income level of community
            \item Size of houses
        \end{itemize}
        And so forth. In this case one might be interested in the association between each individual input variable and housing price. For instance, \emph{how much extra will a house be worth if it has a view of the river?} This is an \textbf{inference problem}.

        \vspace{.5em}
        But \underline{attention}! Alternatively, one may simply be interested in predicting the value of a home given its characteristics: \emph{is this house under or over valued?} And this is a \textbf{prediction problem}.
    \end{examplebox}

    So, as you can see from the example, the difference between a prediction problem and an inference problem is so small. A problem can change its nature because the ultimate goal is also changing.

    \newpage

    \subsection{How do we estimate \emph{f}?}

    We will always assume that we have observed a set of $n$ different data points. For example, in figure~\ref{fig: error term systematic} at page~\pageref{fig: error term systematic} we observed $n=30$ data points. These observations are called \definition{training data} because we will \textbf{use these observations to train, or teach, our method how to estimate} $\bm{f}$.
    
    \highspace
    Let:
    \begin{itemize}
        \item $x_{ij}$ represent the value of the $j$th predictor, or input, for observation $i$, where $i=1,2,\dots,n$ and $j=1,2,\dots,p$
        
        \item $y_{i}$ represent the response variable for the $i$th observation.
    \end{itemize}
    Then, our training data consist of:
    \begin{equation*}
        \left\{\left(x_{1}, y_{1}\right), \left(x_{2}, y_{2}\right), \dots, \left(x_{n}, y_{n}\right)\right\}
    \end{equation*}
    Where $x_{i} = \left(x_{i1}, x_{i2}, \dots, x_{ip}\right)^{T}$.
    
    \highspace
    Our \underline{goal} is to \textbf{apply a statistical learning method to the training data in order to estimate the unknown function} $\bm{f}$. In other words, we want to find a function $\hat{f}$ such that $Y \approx \hat{f}\left(X\right)$ for any observations $\left(X, Y\right)$. Most statistical learning methods for this task can be characterized as either \definition{parametric} or \definition{non-parametric}.
    
    \newpage

    \subsubsection{Parametric Methods}

    The \definition{parametric methods} involve a two-step model-based approach:
    \begin{enumerate}
        \item Select a model.
        \begin{enumerate}
            \item \textbf{Make an assumption about the functional form}, or shape, of $f$. For \example{example}, one very simple assumption is that $f$ is linear in $X$:
            \begin{equation}
                f\left(X\right) = \beta_{0} + \beta_{1}X_{1} + \beta_{2}X_{2} + \cdots + \beta_{p}X_{p}
            \end{equation}
            This is a \definition{linear model} (that will be discussed in the future). Once we have assumed that $f$ is linear, \textbf{the problem of estimating $\bm{f}$ is greatly simplified}. Instead of having to estimate an entirely arbitrary $p$-dimensional function $f\left(X\right)$, one only needs to \textbf{estimate the $\bm{p+1}$ coefficients} $\beta_{0}, \beta_{1}, \dots, \beta_{p}$.
        \end{enumerate}

        \item Use training data to fit/train the model.
        \begin{enumerate}
            \item[(b)] After a model has been selected, we need a \textbf{procedure that uses the training data to} \definition{fit the model} or \definition{train the model}. In the case of the linear method, we need to estimate the parameters $\beta_{0}, \beta_{1}, \dots, \beta_{p}$. So, we want to find values of these parameters such that:
            \begin{equation*}
                Y \approx \beta_{0} + \beta_{1}X_{1} + \beta_{2}X_{2} + \cdots + \beta_{p}X_{p}
            \end{equation*}
            The most \textbf{common approach to fitting} the (linear) model is referred to as (\textbf{ordinary}) \definition{least squares} (that will be discussed in the future). However, the least squares is one of many possible ways to fit the linear model.
        \end{enumerate}
    \end{enumerate}
    The parametric model-based reduces the problem of estimating $f$ down to one of \textbf{estimating a set of parameters}. In fact, assuming a parametric form for $f$ simplifies the problem of estimating $f$ because it is generally much easier to estimate a set of parameters in the linear model, than it is to fit an entirely arbitrary function $f$.

    \begin{flushleft}
        \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Potential disadvantage}}
    \end{flushleft}
    The \textbf{model} we choose will \textbf{usually not match the true unknown form of} $\bm{f}$. If the chosen model is \textbf{too far} from the true $f$, then our \textbf{estimate will be poor}.

    \begin{flushleft}
        \textcolor{Green3}{\faIcon{check} \textbf{Possible (partial) solution}}
    \end{flushleft}
    We can try to address this problem by \textbf{choosing} \definition{flexible models} that can \textbf{fit many different possible functional forms for} $\bm{f}$. But fitting a more flexible model \textbf{requires estimating a greater number of parameters}. 
    
    These more complex models (\textbf{flexible models}) can lead to a phenomenon known as \definition{overfitting} the data, which essentially means \textbf{they follow the errors}, or \definition{noise}, \textbf{too closely} (these issues are discussed throughout this course).

    \newpage

    \subsubsection{Non-Parametric Methods}

    The \definition{non-parametric} methods do not make explicit assumptions about the functional form of $f$. Instead they seek an \textbf{estimate of} $\bm{f}$ \textbf{that gets as close to the data points as possible without being too rough or wiggly}.

    \begin{flushleft}
        \textcolor{Green3}{\faIcon{check} \textbf{Major advantage over parametric approaches}}
    \end{flushleft}
    By avoiding the assumption of a particular functional form for $f$, non-parametric approaches have the \textbf{potential to accurately fit a wider range of possible shapes} for $f$. Any parametric approach brings with it the possibility that the functional form used to estimate $f$ is very different from the true $f$, in which case the resulting model will not fit the data well.

    \begin{flushleft}
        \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Disadvantage}}
    \end{flushleft}
    Since non-parametric approaches do not reduce the problem of estimating $f$ to a small number of parameters, \textbf{a very large number of observations} (far more than is typically needed for a parametric approach) \textbf{is required in order to obtain an accurate estimate} for $f$.

    \newpage

    \subsection{Supervised and Unsupervised Learning}

    Most statistical learning problems fall into one of two categories: \definition{supervised learning} or \definition{unsupervised learning}.

    \longline

    \begin{flushleft}
        \large
        \textbf{Supervised learning}
    \end{flushleft}
    The examples that we have discussed in this chapter all fall into the \definition{supervised learning} domain. For each observation of the predictor measurement(s) $x_{i}, i=1,\dots,n$ there is an associated response measurement $y_{i}$.

    \highspace
    We wish to \textbf{fit a model that relates the response to the predictors}, with the \underline{aim} of:
    \begin{itemize}
        \item \textbf{Accurately predicting the response for future observations} (prediction, section~\ref{subsubsection: prediction})
        \item \textbf{Better understanding the relationship between the response and the predictors} (inference, section~\ref{subsubsection: inference})
    \end{itemize}

    \longline
    
    \begin{flushleft}
        \large
        \textbf{Unsupervised learning}
    \end{flushleft}
    The \definition{unsupervised learning} describes the somewhat more challenging situation in which \textbf{for every observation} $i=1,\dots,n$, \textbf{we observe a vector of measurements} $x_{i}$ \textbf{but no associated response} $y_{i}$. 
    
    \highspace
    In this setting, we are in some sense \emph{working blind}; the situation is referred to as \textbf{unsupervised} because \textbf{we lack a response variable that can supervise our analysis}. We can \textbf{seek to understand the relationships between the variables or between the observations}.

    \newpage

    \subsection{Assessing Model Accuracy}

    The aim of this section is to decide which method will give the best results for a given set of data.

    \subsubsection{Measuring the Quality of Fit (MSE)}

    In order to evaluate the performance of a statistical learning method on a given data set, we need some way to measure how well its predictions actually match the observed data. We need to \textbf{quantify the extent to which the predicted response value for a given observation is close to the true response value for that observation}. The most commonly-used measure is the \definition{mean squared error (MSE)}:
    \begin{equation}\label{eq: mean squared error}
        \mathrm{MSE} = \dfrac{1}{n} \displaystyle\sum_{i=1}^{n} \left(y_{i} - \hat{f}\left(x_{i}\right)\right)^{2}
    \end{equation}
    \begin{itemize}
        \item $\hat{f}\left(x_{i}\right)$ is the prediction that $\hat{f}$ gives for the $i$th observation
        \item $y_{i}$ the $i$th true response
    \end{itemize}
    Obviously,the MSE will be:
    \begin{itemize}
        \item \textbf{Small} if the predicted responses are very close to the true responses;
        \item \textbf{Large} if for some of the observations, the predicted and true responses differ substantially.
    \end{itemize}
    In general, we do not really care how well the method works on the training data. Rather, \textbf{we are interested in the accuracy of the predictions that we obtain when we apply our method to previously unseen test data}.

    \begin{examplebox}
        Suppose that we are interested in developing an algorithm to predict a stock's price based on previous stock returns.

        \highspace
        We can train the method using stock returns from the past 6 months. But we \underline{don't} really care how well our method predicts last week's stock price.

        We instead \textbf{care about how well it predict tomorrow's price or next month's price}.
    \end{examplebox}

    \begin{examplebox}
        Suppose that we have clinical measurements (e.g. weight, blood pressure, height, age, family history of disease) for a number of patients, as well as information about whether each patient has diabetes.

        \highspace
        We can use these patients to train a statistical learning method to predict risk of diabetes based on clinical measurements.

        \highspace
        In practice, \textbf{we want this method to accurately predict diabetes risk for \emph{future patients} based on their clinical measurements}. Again, we are \underline{not} very interested in whether or not the method accurately predicts diabetes risk for patients used to train the mode, since \underline{we already know which of those patients have diabetes}!
    \end{examplebox}

    \noindent
    In mathematical terms, suppose that we fit our statistical learning method on our training observations:
    \begin{equation*}
        \left\{\left(x_{1}, y_{1}\right), \left(x_{2}, y_{2}\right), \dots, \left(x_{n}, y_{n}\right)\right\}
    \end{equation*}
    And we obtain the estimate $\hat{f}$. We can then compute:
    \begin{equation*}
        \hat{f}\left(x_{1}\right), \hat{f}\left(x_{2}\right), \dots, \hat{f}\left(x_{n}\right)
    \end{equation*}
    If these are approximately equal to:
    \begin{equation*}
        y_{1}, y_{2}, \dots, y_{n}
    \end{equation*}
    Then \textbf{the training MSE is small}.

    \highspace
    However, we are really \underline{not interested} in whether $\hat{f}\left(x_{i}\right) \approx y_{i}$; instead, we want to know whether $\hat{f}\left(x_{0}\right)$ is approximately equal to $y_{0}$, where $\left(x_{0}, y_{0}\right)$ is a \textbf{previously unseen test observation not used to train the statistical learning method}.

    We \textbf{want to choose the method that gives the lowest} \definition{test mean squared error (MSE)}, as opposed to the lowest training MSE. In other words, if we had a large number of test observations, we could compute:
    \begin{equation}
        \mathrm{Ave}\left(y_{0} - \hat{f}\left(x_{0}\right)\right)^{2}
    \end{equation}
    The \textbf{average squared prediction error for these test observations} $\left(x_{0}, y_{0}\right)$.

    \begin{flushleft}
        \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Problem to find the lowest training MSE}}
    \end{flushleft}
    There is \underline{no guarantee} that the method with the lowest training MSE will also have the lowest test MSE. 
    
    The problem is that \textbf{many statistical methods specifically estimate coefficients so as to minimize the training set MSE}. For these methods, the \textbf{training set MSE can be quite small}, \textbf{but the test MSE is often much larger}.
    
    \newpage

    \begin{figure}[!htp]
        \begin{examplebox}
            \begin{center}
                \includegraphics[width=\textwidth]{img/measuring-the-quality-of-fit-1.pdf}
                \captionof{figure}{On the left: \emph{data simulated from $f$, shown in black. Three estimates of $f$ are shown: the linear regression (orange curve), and two smoothing spline fits (blue and green curves)}. Right: \emph{Training MSE (grey curve), test MSE (red curve), and minimum possible test MSE over all methods (dashed line). Squares represent the training and test MSEs for the three fits shown in the left-hand panel}.\cite{james2013introduction}}
                \label{fig: measuring the quality of fit}
            \end{center}
            In the left-hand panel we have generated observations from the (error term\index{error term}) equation~\ref{eq: error term systematic} with the true $f$ given by the black curve. 
            
            The orange, blue and green curves illustrate three possible estimates for $f$ obtained using methods with increasing levels of flexibility.

            \highspace
            It is clear that as the \textbf{level of flexibility increases}, the \textbf{curves fit the observed data more closely}. 
            
            The \emph{green curve} is the most flexible and matches the data very well; however, we observe that it fits the true $f$ (shown in black) poorly because it is too wiggly. 
            
            By \textbf{adjusting the level of flexibility} of the smoothing spline fit, we can \textbf{produce many different fits to this data}.
        \end{examplebox}
    \end{figure}

    \setcounter{example}{9}
    \newpage

    \begin{examplebox}
        \begin{center}
            Referring to Figure~\ref{fig: measuring the quality of fit}
        \end{center}

        We now move on to the right-hand panel. The grey curve displays the average training MSE as a function of flexibility, or more formally the \definition{degrees of freedom}\footnote{The degrees of freedom is a \textbf{quantity that summarizes the flexibility of a curve}.}, for a number of smoothing splines.

        The orange, blue and green squares indicate the MSEs associated with the corresponding curve in the left-hand panel.

        A more restricted and hence smoother curve has fewer degrees of freedom than a wiggly curve. The \emph{linear regression} is at the most restrictive end, with two degrees of freedom.

        \highspace
        The \textbf{training MSE declines monotonically as flexibility increases}. In this example, the true $f$ is non-linear, and so the orange linear fit is not flexible enough to estimate $f$ well. 
        
        The \emph{green curve} has the lowest training MSE of all three methods, since it corresponds to the most flexible of the three curves fit in the left-hand panel.

        \highspace
        The test MSE is displayed using the red curve. As with the training MSE, the test MSE initially declines as the level of flexibility increases.

        At some point, the test MSE levels off and then starts to increase again. Consequently, the orange and green curves both have high test MSE. The blue curve minimizes the test MSE, which should not be surprising given that visually it appears to estimate $f$ the best in the left-hand panel.

        The horizontal dashed line indicates $\Var\left(\varepsilon\right)$, the \textbf{irreducible error} (eq.~\ref{eq: reducible and irreducible error}), which \textbf{corresponds to the lost achievable test MSE among all possible methods}. Hence, the smoothing spline represented by \textbf{the blue curve is close to optimal}.
    \end{examplebox}

    In the right-hand panel of figure~\ref{fig: measuring the quality of fit}, as the flexibility of the Statistical learning method increases, we observe a \textbf{monotone decrease in the training MSE and a U-shape} in the test MSE. This is a \textbf{fundamental property} of statistical learning that holds regardless of the particular data set at hand and regardless of the Statistical method being used.
    
    As model flexibility increases, the training MSE will decrease, but the test MSE may not. \textbf{When a given method yields a small training MSE but a large test MSE}, we are said to be \definition{overfitting} the data.

    \begin{flushleft}
        \textcolor{Green3}{\faIcon{question-circle} \textbf{Why does this phenomenon happen?}}
    \end{flushleft}
    This happens because our \textbf{statistical learning procedure} is working too hard to find patterns in the training data, and \textbf{may be picking up some patterns that are just caused by random chance} rather than by true properties of the unknown function $f$.

    \noindent
    So when we \emph{overfit} the training data, the \textbf{test MSE} will be \textbf{very large because the supposed patterns that the method found in the training data simply don't exist in the test data}.

    \highspace
    We almost \underline{always} expect the \textbf{training MSE to be smaller than the test MSE} because most \textbf{statistical learning methods} either directly or indirectly seek to \textbf{minimize the training MSE}. \emph{Overfitting} refers specifically to the test case in which a \textbf{less flexible model would have yielded a smaller test MSE}.

    \begin{figure}[!htp]
        \begin{examplebox}
            \begin{center}
                \includegraphics[width=\textwidth]{img/measuring-the-quality-of-fit-2.pdf}
                \captionof{figure}{Details are as in Figure~\ref{fig: measuring the quality of fit}, using a different true $f$ that is much closer to linear. In this setting, linear regression provides a very good fit to the data.\cite{james2013introduction}}
                \label{fig: measuring the quality of fit - 2}
            \end{center}

            This figure provides another \example{example} in which the true $f$ is approximately linear. Again we observe that the training MSE decreases monotonically as the model flexibility increases, and that there is a \emph{U-shape} in the test MSE. 
            
            \highspace
            However, because the truth is close to linear, the \textbf{test MSE only decreases slightly before increasing again}, so that the \textbf{orange least squares fit is substantially better than the highly flexible green curve}.
        \end{examplebox}
    \end{figure}

    \begin{figure}[!htp]
        \begin{examplebox}
            \begin{center}
                \includegraphics[width=\textwidth]{img/measuring-the-quality-of-fit-3.pdf}
                \captionof{figure}{Details are as in Figure~\ref{fig: measuring the quality of fit}, using a different true $f$ that is far from linear. In this setting, linear regression provides a very poor fit to the data.\cite{james2013introduction}}
                \label{fig: measuring the quality of fit - 3}
            \end{center}

            Finally, this figure displays an \example{example} in which $f$ is highly non-linear.

            \highspace
            The training and test MSE curves still exhibit the same general patterns, but now there is a rapid decrease in both curves before the test MSE start to increase slowly.
        \end{examplebox}
    \end{figure}
    
    \newpage

    \subsubsection{The Bias-Variance Trade-Off}

    The U-shape observed in the test MSE curves (Figures: \ref{fig: measuring the quality of fit}, \ref{fig: measuring the quality of fit - 2}, \ref{fig: measuring the quality of fit - 3}) turns out to be the result of two competing properties of statistical learning methods. 
    
    \highspace
    The expected test MSE, for a given value $x_{0}$, can always be decomposed into the sum of three fundamental quantities:
    \begin{itemize}
        \item The \definition{variance} of $\hat{f}\left(x_{0}\right)$
        
        \item The squared \definition{bias} of $\hat{f}\left(x_{0}\right)$
        
        \item The \textbf{variance of the error terms} $\bm{\varepsilon}$
    \end{itemize}
    \begin{equation}\label{eq: expected test MSE}
        E\left(y_{0} - \hat{f}\left(x_{0}\right)\right)^{2} = \Var\left(\hat{f}\left(x_{0}\right)\right) + \left[\Bias\left(\hat{f}\left(x_{0}\right)\right)\right]^{2} + \Var\left(\varepsilon\right)
    \end{equation}
    Where $E\left(y_{0} - \hat{f}\left(x_{0}\right)\right)^{2}$ defines the \definition{expected test MSE} at $x_{0}$ and refers to the \textbf{average test MSE} that we would obtain if we \textbf{repeatedly estimated} $\bm{f}$ \textbf{using a large number of training sets, and tested each at} $x_{0}$.

    \highspace
    The equation \ref{eq: expected test MSE} tell us that in order to minimize the expected test error, we need to \textbf{simultaneously select a statistical learning method that} achieves \textbf{\underline{low} variance and \underline{low} bias}. Note that variance is inherently a nonnegative quantity, and squared bias is also nonnegative. Hence, we see that the expected test MSE can never lie below $\Var\left(\varepsilon\right)$, the irreducible error (equation~\ref{eq: reducible and irreducible error}).

    \begin{flushleft}
        \textcolor{Red2}{\faIcon[regular]{star} \textbf{Meaning of the variance}}
    \end{flushleft}
    The \definition{variance} refers to the \textbf{amount by which} $\bm{\hat{f}}$ \textbf{would change if we estimated it using a different training data set}. So different training data sets will result in a different $\hat{f}$. But ideally the estimate for $f$ should not vary too much between training sets. However, \textbf{if a method has high variance then small changes in the training data can result in large changes in} $\bm{\hat{f}}$. 
    
    \noindent
    In general, \textbf{more flexible statistical methods have higher variance}.

    \begin{examplebox}
        Consider the green and the orange curves in Figure~\ref{fig: measuring the quality of fit} at page~\pageref{fig: measuring the quality of fit}.
        
        \highspace
        The flexible green curve is following the observations very closely. It has high variance because changing any one of these data points may cause the estimate $\hat{f}$ to change considerably. 
        
        \highspace
        In contrast, the orange least squares line is relatively inflexible and has low variance, because moving any single observations will likely cause only a small shift in the position of the line.
    \end{examplebox}

    \newpage

    \begin{flushleft}
        \textcolor{Red2}{\faIcon[regular]{star} \textbf{Meaning of the bias}}
    \end{flushleft}
    The \definition{bias} refers to the \textbf{error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much simpler model}.

    \begin{examplebox}
        For \example{example}, linear regression assumes that there is a linear relationship between $Y$ and $X_{1}, X_{2}, \dots, X_{p}$. It is unlikely that any real-life problem truly has such a simple linear relationship, and so performing linear regression will undoubtedly result in some bias in the estimate of $f$.

        \highspace
        In the Figure~\ref{fig: measuring the quality of fit - 3} on page \pageref{fig: measuring the quality of fit - 3}, the true $f$ is substantially non-linear, so no matter how many training observations we are given, it will not be possible to produce an accurate estimate using linear regression. In other words, linear regression results in high bias in this example.

        \highspace
        However, in Figure~\ref{fig: measuring the quality of fit - 2} on page \pageref{fig: measuring the quality of fit - 2} the true $f$ is very close to linear, and so given enough data, it should be possible for linear regression to produce an accurate estimate.
    \end{examplebox}

    \noindent
    Generally, as we use \textbf{more flexible methods}, the \definition{variance} \textbf{will increase} and the \definition{bias} \textbf{will decrease}.

    \highspace
    As we increase the flexibility of a class of methods, the bias tends to initially decrease faster than the variance increases. Consequently, the expected test MSE declines. However, at some point increasing flexibility has little impact on the bias but starts to significantly increase the variance. When this happens the test MSE increases. Note that we observed this pattern of decreasing test MSE followed by increasing test MSE in the right-hand panels of Figures \ref{fig: measuring the quality of fit}, \ref{fig: measuring the quality of fit - 2}, \ref{fig: measuring the quality of fit - 3}. In summary:
    \begin{enumerate}
        \item We increase the flexibility of a class of methods;
        \item The bias tends to initially decrease faster than the variance increases;
        \item The expected test MSE declines;
        \item At some point increasing flexibility has little impact on the bias but starts to significantly increase the variance;
        \item The test MSE increases.
    \end{enumerate}

    \newpage

    \begin{figure}[!htp]
        \begin{examplebox}
            \begin{center}
                \includegraphics[width=\textwidth]{img/the-bias-variance-trade-off-1.pdf}
                \captionof{figure}{Squared bias (blue curve), variance (orange curve), $\Var\left(\varepsilon\right)$ (dashed line), and test MSE (red curve) for the three data sets in Figures \ref{fig: measuring the quality of fit}, \ref{fig: measuring the quality of fit - 2}, \ref{fig: measuring the quality of fit - 3}. The vertical dotted line indicates the flexibility level corresponding to the smallest test MSE.\cite{james2013introduction}}
                \label{fig: the bias-variance trade-off}
            \end{center}

            Three plots illustrate equation~\ref{eq: expected test MSE} on page~\pageref{eq: expected test MSE} for the examples in Figure \ref{fig: measuring the quality of fit}, \ref{fig: measuring the quality of fit - 2}, \ref{fig: measuring the quality of fit - 3}.

            In each case the blue solid curve represents the squared bias, for different levels of flexibility, while the orange curve corresponds to the variance. The horizontal dashed line represents $\Var\left(\varepsilon\right)$, the irreducible error. Finally, the red curve, corresponding to the test set MSE, is the sum of these three quantities. 
            
            \highspace
            In all three cases, the variance increases and the bias decreases as the method's flexibility increases. However, the flexibility level corresponding to the optimal test MSE differs considerably among the three data sets, because the squared bias and variance change at different rates in each of the data sets. 
            
            \highspace
            In the left-hand panel of this Figure, the bias initially decreases rapidly, resulting in an initial sharp decrease in the expected test MSE. 
            
            \highspace
            On the other hand, in the center panel of this Figure the true $f$ is close to linear, so there is only a small decrease in bias as flexibility increases, and the test MSE only declines slightly before increasing rapidly as the variance increases. 
            
            \highspace
            Finally, in the right-hand panel of this Figure, as flexibility increases, there is a dramatic decline in bias because the true $f$ is very non-linear. There is also very little increase in variance as flexibility increases. Consequently, the test MSE declines substantially before experiencing a small increase as model flexibility increases.
        \end{examplebox}
    \end{figure}

    \newpage

    \begin{flushleft}
        \textcolor{Red2}{\faIcon[regular]{star} \textbf{Meaning of the bias-variance trade-off}}
    \end{flushleft}
    The relationship between bias, variance, and test set MSE given in equation~\ref{eq: expected test MSE} on page~\pageref{eq: expected test MSE} and displayed in the Figure~\ref{fig: the bias-variance trade-off} (previous example) is referred to as the \definition{bias-variance trade-off}. 
    
    \highspace
    Good test set performance of a statistical learning method requires low variance as well as low squared bias. This is referred to as a \textbf{trade-off} because it is \textbf{easy to obtain a method with extremely low bias but high variance}\footnote{For \example{instance}, by drawing a curve that passes through every single training observation} or \textbf{a method with very low variance but high bias} (by fitting a horizontal line to the data).
    
    \highspace
    The \textbf{challenge lies in finding a method for which both the variance and the squared bias are low}. This trade-off is one of the most important recurring themes in this course.

    \newpage

    \subsection{Algorithm: K-Nearest Neighbors (KNN)}

    Many approaches attempt to \textbf{estimate the conditional distribution of} $\bm{Y}$ \textbf{given} $\bm{X}$, and \textbf{then classify a given observation to the class} with \textbf{highest estimated probability}. One such method is the \definition{K-nearest neighbors (KNN)} classifier.

    \highspace
    In mathematical terms, given a positive integer $K$ and a test observation $x_{0}$ the KNN classifier:
    \begin{enumerate}
        \item \textbf{Identifies} the $K$ points in the training data that are closest to $x_{0}$, represented by $\mathcal{N}_{0}$.
        
        \item It then \textbf{estimates} the conditional probability for class $j$ as the fraction of points in $\mathcal{N}_{0}$ whose response values equal $j$:
        \begin{equation}\label{eq: KNN}
            \Pr\left(Y=J \: | \: X=x_{0}\right) = \dfrac{1}{K} \displaystyle\sum_{i \in \mathcal{N}_{0}} I\left(y_{i} = j\right)
        \end{equation}

        \item Finally, KNN \textbf{classifies} the test observation $x_{0}$ to the class with the largest probability from the previous equation.
    \end{enumerate}
    
    \begin{examplebox}
        Suppose that we choose $K=3$. Then KNN algorithm:
        \begin{enumerate}
            \item Identify the three observations that are closet to the cross. As you can see in the Figure~\ref{fig: KNN} on page~\pageref{fig: KNN}, this neighborhood is shown as a circle. It consists of two blue points and one orange point, resulting in estimated probabilities of $\dfrac{2}{3}$ for the blue class and $\dfrac{1}{3}$ for the orange class.
            
            \item Hence, KNN will predict that the black cross belongs to the blue class.
        \end{enumerate}
    \end{examplebox}

    \newpage

    \begin{figure}[!htp]
        \begin{examplebox}
            \begin{center}
                \includegraphics[width=\textwidth]{img/KNN-1.pdf}
                \captionof{figure}{The KNN approach, using $K=3$, is illustrated in a simple situation with six blue observations and six orange observations. Left: \emph{a test observation at which a predicted class label is desired is shown as a black cross. The three closest points to the test observation are identified, and it is predicted that the test observation belongs to the most commonly-occurring class, in this case blue}. Right: \emph{the KNN decision boundary for this example is shown in black. The blue grid indicates the region in which a test observation will be assigned to the blue class, and the orange grid indicates the region in which it will be assigned to the orange class}.}
                \label{fig: KNN}
            \end{center}

            This figure provides an illustrative example of the KNN approach. In the left-hand panel, we have plotted a small training data set consisting of six blue and six orange observations. Our goal is to make a prediction for the point labeled by the black cross.

            \highspace
            In the right-hand panel, we have applied the KNN approach with $K=3$ at all of the possible values for $X_{1}$ and $X_{2}$, and have drawn in the corresponding KNN decision boundary.
        \end{examplebox}
    \end{figure}

    \newpage

    \begin{figure}[!htp]
        \begin{examplebox}
            \begin{center}
                \includegraphics[width=\textwidth]{img/KNN-2.pdf}
                \captionof{figure}{The black curve indicates the KNN decision boundary on the data, using $K=10$. The Bayes decision boundary is shown as a purple dashed line. The KNN and Bayes decision boundaries are very similar.}
                \label{fig: KNN 2}
            \end{center}

            This Figure displays the KNN decision boundary, using $K=10$, when applied to the larger simulated data set.
        \end{examplebox}
    \end{figure}


















    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Laboratory %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \newpage

    \section{R language programming}

    \subsection{Introduction to R}

    There is no introduction to RStudio in these notes. But you can find a detailed guide \href{https://moderndive.netlify.app/1-getting-started#getting-started}{here}.

    \highspace
    \texttt{R} uses functions to perform operations. To run a function called \texttt{funcname}, we type \texttt{funcname(input1, input2)}, where the inputs (or arguments) \texttt{input1} and \texttt{input2} tell \texttt{R} how to run the function.

    \newpage

    \subsubsection{Scalars, vectors and matrices}

    \begin{itemize}
        \item Create a \textbf{scalar}
        \lstinputlisting[language=R]{code/scalars-1.r}

        \item Create a \textbf{vector}
        \lstinputlisting[language=R]{code/vectors-1.r}
        And the result is always the same:
        \lstinputlisting{code/output-vectors-1}
        \begin{itemize}
            \item \texttt{c} function (\href{https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/c}{documentation}) takes $n$ arguments to create a vector of length $n$.

            \item \texttt{seq} function (\href{https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/seq}{doc}) takes two arguments to create a vector with these two values as its lower and upper bound. In the example code, the values are passed implicitly, but we can make them explicit with \texttt{from} and \texttt{to}:
            \lstinputlisting[language=R]{code/vectors-2.r}
            And the result is always the same:
            \lstinputlisting{code/output-vectors-1}
            The \texttt{len} parameter specifies the length of the vector. For example:
            \lstinputlisting[language=R]{code/vectors-3.r}
            And the result is:
            \lstinputlisting{code/output-vectors-3}
            With the \texttt{by} argument, we can increment the sequence:
            \lstinputlisting[language=R]{code/vectors-4.r}
            And the result is:
            \lstinputlisting{code/output-vectors-4}

            \item The \texttt{:} (colon operator, \href{https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/Colon}{doc}) generates a regular sequence. It's very easy to use: \texttt{from:to}.
        \end{itemize}

        \item Create a \textbf{matrix}
        \lstinputlisting[language=R]{code/matrices-1.r}
        And the result is always the same:
        \lstinputlisting{code/output-matrices-1}
        \begin{itemize}
            \item The \texttt{rbind} and \texttt{cbind} (\href{https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/cbind}{doc}) functions are very similar. Both take a sequence of vector, matrix or data-frame arguments and combine by rows or columns, respectively. So if we use \texttt{rbind}, we need to specify the lines. If we use \texttt{cbind} instead, we need to specify each column.
            
            A useful piece of advice when using \texttt{rbind} or \texttt{cbind} is the code style. The following code is easier to read:
            \lstinputlisting[language=R]{code/matrices-2.r}
            We can also convert a vector into a row vector with \texttt{rbind} or a column vector with \texttt{cbind}.

            \item The \texttt{matrix} (\href{https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/matrix}{doc}) function creates a matrix from the given set of values. The arguments:
            \begin{itemize}
                \item \texttt{data} is an optional data vector.
                \item \texttt{nrow} is the desired number of rows.
                \item \texttt{ncol} is the desired number of columns.
                \item \texttt{byrow} is a logical argument. If \texttt{FALSE} (or \texttt{F}, the default) the matrix is filled by columns, otherwise the matrix is filled by rows.
            \end{itemize}
            \lstinputlisting[language=R]{code/matrices-3.r}
        \end{itemize}
    \end{itemize}

    \subsubsection{Access elements}

    We can access to an \textbf{element of a vector} using the square brackets.
    \begin{itemize}
        \item By explicitly inserting the index
        \lstinputlisting[language=R]{code/access-elements-1.r}

        \item By explicitly inserting a vector as an index to access multiple elements
        \lstinputlisting[language=R]{code/access-elements-2.r}

        \item By explicitly inserting a negative value as an index to access all values except the specified index value (is the opposite of a positive index value)
        \lstinputlisting[language=R]{code/access-elements-3.r}

        \item By explicitly inserting a negative vector as an index to access all values except the specified vector value (is the opposite of a positive vector value)
        \lstinputlisting[language=R]{code/access-elements-4.r}
    \end{itemize}
    We can access to an \textbf{element of a matrix} using the square brackets.
    \begin{itemize}
        \item By explicitly inserting the index
        \lstinputlisting[language=R]{code/access-elements-5.r}

        \item By explicitly inserting a vector as an index (column or row) to access multiple elements
        \lstinputlisting[language=R]{code/access-elements-6.r}

        \item By explicitly inserting a blank to access all values of the row/column
        \lstinputlisting[language=R]{code/access-elements-7.r}
    \end{itemize}

    \newpage

    \subsubsection{Algebraic operations}

    By default, operations in \texttt{R} are performed on a component-by-component basis. For example, given the following data:
    \lstinputlisting[language=R, firstline=1, lastline=7]{code/algebraic-operations-1.r}
    \begin{itemize}
        \item Sum between two scalars
        \lstinputlisting[language=R, firstline=9, lastline=10]{code/algebraic-operations-1.r}

        \item Sum between two vectors
        \lstinputlisting[language=R, firstline=11, lastline=12]{code/algebraic-operations-1.r}

        \item Multiply between two scalars
        \lstinputlisting[language=R, firstline=13, lastline=14]{code/algebraic-operations-1.r}

        \item Multiply between two vectors
        \lstinputlisting[language=R, firstline=15, lastline=16]{code/algebraic-operations-1.r}

        \item Sum between a vector and a scalar
        \lstinputlisting[language=R, firstline=17, lastline=18]{code/algebraic-operations-1.r}

        \item Exponential of a vector
        \lstinputlisting[language=R, firstline=19, lastline=20]{code/algebraic-operations-1.r}
    \end{itemize}
















    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% END %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


    \newpage

    \bibliography{bibtex}{}
    \bibliographystyle{plain}

    \newpage

    \printindex
\end{document}