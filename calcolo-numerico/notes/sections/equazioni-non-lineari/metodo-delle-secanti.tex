\subsection{Il metodo delle secanti}

Nel caso in cui la funzione $f$ non sia nota, il metodo di Newton non può essere applicato. Per fortuna, arriva in soccorso il \definition{metodo delle secanti}, il quale esegue una valutazione di $f'\left(x^{(k)}\right)$ andando a sostituire quest'ultima con un \textbf{rapporto incrementale calcolato su valori di $f$ già noti}.

\highspace
Più formalmente, assegnati due punti $x^{(0)}$ e $x^{(1)}$, per $k \ge 1$ si calcola:
\begin{equation}
    x^{(k+1)} = x^{(k)} - \left(\dfrac{f\left(x^{(k)}\right) - f\left(x^{(k-1)}\right)}{x^{(k)} - x^{(k-1)}}\right)^{-1} \cdot f\left(x^{(k)}\right)
\end{equation}

\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{Quando converge?}}
\end{flushleft}
Il metodo delle secanti converge a seguito di certe condizioni:
\begin{itemize}
    \item \textbf{Converge ad} $\bm{\alpha}$, se:
    \begin{itemize}
        \item $\alpha$ radice semplice\footnote{$f'\left(\alpha\right) \ne 0$};
        \item $I\left(\alpha\right)$ è un opportuno intorno di $\alpha$;
        \item $x^{(0)}$ e $x^{(1)}$ sono sufficientemente vicini ad $\alpha$
        \item $f'\left(x\right) \ne 0$ $\forall x \in I\left(\alpha\right) \setminus \left\{\alpha\right\}$
    \end{itemize}

    \item \textbf{Converge con ordine} \definition{$p$ super-lineare}, se:
    \begin{itemize}
        \item $f \in \mathcal{C}^{2}\left(I\left(\alpha\right)\right)$
        \item $f'\left(\alpha\right) \ne 0$
    \end{itemize}
    Ovvero, esiste una costante $c > 0$ tale che:
    \begin{equation}
        \left| x^{\left(k+1\right)} - \alpha\right| \le c\left| x^{(k)} - \alpha \right|^{p} \hspace{2em} p = \dfrac{1 + \sqrt{5}}{2} \approx 1.618\dots
    \end{equation}

    \item \textbf{Convergenza lineare}, se:
    \begin{itemize}
        \item Radice $\alpha$ è multipla.
    \end{itemize}
    Come succederebbe usando il metodo di Newton.
\end{itemize}

% TODO: pag. 59